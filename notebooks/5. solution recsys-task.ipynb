{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework\n",
    "\n",
    "In the lectures, we discussed the Jaccard measure and how to calculate it efficiently on MapReduce.\n",
    "\n",
    "You are invited to calculate the Jaccard measure on Spark to find similar performers in the entire dataset and answer the following questions:\n",
    "1. **How many performers remain in consideration after applying all filters from the job description?**\n",
    "2. **For how many pairs of performers did you manage to calculate non-zero similarity according to Jaccard? Here, all possible pairs (a, b) and (b, a) are taken into account, as well as (a, a), to check the correctness.**\n",
    "3. **Find the 5 most similar artists to \"Maroon 5\" by Jaccard's calculated measure. As a result, write down the names of 5 artists other than \"Maroon 5\".**\n",
    "\n",
    "Несколько напутственных слов:\n",
    "- Use the data loaded in the <a href=\"#Loading-data\">Loading-data</a> section.\n",
    "- Users who listened to $N$ artists will contribute to the similarity of $N^2$ pairs of artists. Therefore, rare very active users will greatly slow down our algorithm. For such users, in practice, take a subset of plays, for example, 1000. We will do it easier and will only consider plays where $plays > 2$, thus leaving only the most confident user preferences.\n",
    "- To make the similarities more confident, we will consider them only for those performers who were strictly listened to by more than 50 people (taking into account the previous filter by auditions).\n",
    "- To debug the algorithm on a smaller amount of data, you can use the transformation <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.sample\">events.sample(False , 0.01)</a> so as not to wait long for debug runs.\n",
    "- We can assume that data about performers (for example, their popularity) will fit in the memory of each machine. There just aren't that many performers in the world that won't fit.\n",
    "- If a step takes a very long time, you can increase the degree of parallelism, for example,\n",
    "<a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.groupByKey\">groupByKey(numPartitions=100)</a> to see more granular progress execution.\n",
    "- Sometimes it makes sense to save the calculated result in HDFS, so as not to recalculate it again every time it is needed.\n",
    "- When working with big data, patience is required, the author's solution works for about 10 minutes.\n",
    "- This problem can also be solved in Spark SQL, if you like it better.\n",
    "\n",
    "Save the solution to the `result.json` file. \n",
    "File content example:\n",
    "```json\n",
    "{\n",
    "    \"q1\": 123,\n",
    "    \"q2\": 456,\n",
    "    \"q3\": [\n",
    "        \"artistName1\",\n",
    "        \"artistName2\",\n",
    "        \"artistName3\",\n",
    "        \"artistName4\",\n",
    "        \"artistName5\"\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copyFromLocal: `/yandex_music/events.csv': File exists\n",
      "copyFromLocal: `/yandex_music/artists.jsonl': File exists\n",
      "copyFromLocal: `/yandex_music/README.txt': File exists\n",
      "copyFromLocal: `/yandex_music/untitled.txt': File exists\n",
      "copyFromLocal: `/yandex_music/.ipynb_checkpoints/artists-checkpoint.jsonl': File exists\n",
      "copyFromLocal: `/yandex_music/.ipynb_checkpoints/README-checkpoint.txt': File exists\n",
      "copyFromLocal: `/yandex_music/.ipynb_checkpoints/untitled-checkpoint.txt': File exists\n"
     ]
    }
   ],
   "source": [
    "! hadoop fs -copyFromLocal yandex_music /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 items\n",
      "drwxr-xr-x   - jovyan supergroup          0 2023-04-09 16:02 /yandex_music/.ipynb_checkpoints\n",
      "-rw-r--r--   1 jovyan supergroup        254 2023-04-08 12:14 /yandex_music/README.txt\n",
      "-rw-r--r--   1 jovyan supergroup      3.7 M 2023-04-08 12:14 /yandex_music/artists.jsonl\n",
      "-rw-r--r--   1 jovyan supergroup     47.6 M 2023-04-08 12:14 /yandex_music/events.csv\n",
      "-rw-r--r--   1 jovyan supergroup          0 2023-04-09 16:02 /yandex_music/untitled.txt\n"
     ]
    }
   ],
   "source": [
    "! hadoop fs -ls -h /yandex_music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "2023-04-21 13:40:07,950 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "sc = pyspark.SparkContext(appName='week-5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Row\n",
    "se = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "artists = se.read.json(\"hdfs:///yandex_music/artists.jsonl\")\n",
    "artists.registerTempTable(\"artists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "events = se.read.csv(\"hdfs:///yandex_music/events.csv\", header=True, \n",
    "                     schema='userId bigint, artistId bigint, plays INT, skips INT')\n",
    "events.registerTempTable(\"events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "se.sql(\"\"\"select distinct userId, artistId from events where plays > 2\"\"\").registerTempTable(\"cond1_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 31:===================================================>    (11 + 1) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|userId|artistId|\n",
      "+------+--------+\n",
      "|     2|   66150|\n",
      "|     3|   40096|\n",
      "|     3|   60021|\n",
      "|     3|    8452|\n",
      "|     4|   68294|\n",
      "+------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "se.sql(\"\"\"select artistId, count(*) as popularity from cond1_table group by artistId\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "se.sql(\"\"\"select * from (select artistId, count(*) as popularity from cond1_table group by artistId) where popularity>50\"\"\").registerTempTable(\"cond2_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "se.sql(\"\"\"select userId, events.artistId, plays, popularity from cond2_table as s join events on s.artistId = events.artistId where plays > 2 order by userId, artistId\"\"\").registerTempTable(\"cond3_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "se.sql(\"\"\"select userId, artistId from cond3_table group by userId, artistId order by userId, artistId\"\"\").registerTempTable(\"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Table or view not found: temp1; line 9 pos 21;\n'Sort ['userId ASC NULLS FIRST, 'artistId ASC NULLS FIRST], true\n+- 'Aggregate ['userId, 'artistId], ['userId, 'artistId]\n   +- 'SubqueryAlias __auto_generated_subquery_name\n      +- 'Sort ['userId ASC NULLS FIRST, 'artistId ASC NULLS FIRST], true\n         +- 'Project ['userId, 'events.artistId, 'plays, 'popularity]\n            +- 'Filter ('plays > 2)\n               +- 'Join Inner, ('s.artistId = 'events.artistId)\n                  :- 'SubqueryAlias s\n                  :  +- 'Project [*]\n                  :     +- 'Filter ('popularity > 50)\n                  :        +- 'SubqueryAlias __auto_generated_subquery_name\n                  :           +- 'Aggregate ['artistId], ['artistId, count(1) AS popularity#148L]\n                  :              +- 'UnresolvedRelation [temp1], [], false\n                  +- SubqueryAlias events\n                     +- View (`events`, [userId#11L,artistId#12L,plays#13,skips#14])\n                        +- Relation [userId#11L,artistId#12L,plays#13,skips#14] csv\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[43mse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;43;03m\"\"\"\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;43;03mselect userId, artistId\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;43;03mfrom(\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;43;03m    select userId, events.artistId, plays, popularity\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;43;03m    from   (\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;43;03m            select *\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;43;03m            from(\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;43;03m                select artistId, count(*) as popularity\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;43;03m                from temp1\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;43;03m                group by artistId\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;43;03m                )\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;43;03m            where popularity > 50\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;43;03m             )as s join events on s.artistId = events.artistId\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;43;03m    where plays > 2\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;43;03m    order by userId, artistId\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;43;03m    )\u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;43;03mgroup by userId, artistId\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;43;03morder by userId, artistId\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;43;03m\"\"\"\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# table.show()\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py:723\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msql\u001b[39m(\u001b[38;5;28mself\u001b[39m, sqlQuery):\n\u001b[1;32m    708\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a :class:`DataFrame` representing the result of the given query.\u001b[39;00m\n\u001b[1;32m    709\u001b[0m \n\u001b[1;32m    710\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 2.0.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;124;03m    [Row(f1=1, f2='row1'), Row(f1=2, f2='row2'), Row(f1=3, f2='row3')]\u001b[39;00m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 723\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrapped)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    113\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Table or view not found: temp1; line 9 pos 21;\n'Sort ['userId ASC NULLS FIRST, 'artistId ASC NULLS FIRST], true\n+- 'Aggregate ['userId, 'artistId], ['userId, 'artistId]\n   +- 'SubqueryAlias __auto_generated_subquery_name\n      +- 'Sort ['userId ASC NULLS FIRST, 'artistId ASC NULLS FIRST], true\n         +- 'Project ['userId, 'events.artistId, 'plays, 'popularity]\n            +- 'Filter ('plays > 2)\n               +- 'Join Inner, ('s.artistId = 'events.artistId)\n                  :- 'SubqueryAlias s\n                  :  +- 'Project [*]\n                  :     +- 'Filter ('popularity > 50)\n                  :        +- 'SubqueryAlias __auto_generated_subquery_name\n                  :           +- 'Aggregate ['artistId], ['artistId, count(1) AS popularity#148L]\n                  :              +- 'UnresolvedRelation [temp1], [], false\n                  +- SubqueryAlias events\n                     +- View (`events`, [userId#11L,artistId#12L,plays#13,skips#14])\n                        +- Relation [userId#11L,artistId#12L,plays#13,skips#14] csv\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "498589"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "df = table.groupBy('userId').agg(F.collect_list(\"artistId\").alias('pairs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1_1', '1_2', '1_3', '2_1', '2_2', '2_3', '3_1', '3_2', '3_3']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(list_):\n",
    "    lis = []\n",
    "    for i in list_:\n",
    "        for j in list_:\n",
    "#             if j>=i:\n",
    "                lis.append('{}_{}'.format(i, j))\n",
    "    return lis\n",
    "f([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "udf_f = udf(f, ArrayType(StringType()))\n",
    "pairs = df.withColumn(\"pairs\", udf_f(col(\"pairs\"))).select('pairs')\n",
    "big_col = pairs.select(explode('pairs'))\n",
    "cnt_col = big_col.groupBy('col').count().sort(desc('count'))\n",
    "split = cnt_col.withColumn('A', split(cnt_col['col'], '_').getItem(0)) \\\n",
    "       .withColumn('B', split(cnt_col['col'], '_').getItem(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "listenings = table.groupby('artistId').count().sort(desc('count')).toPandas().set_index('artistId')\n",
    "def artist_to_listenings(id_):\n",
    "    return int(listenings.loc[int(id_)].values[0])\n",
    "\n",
    "AtoL = udf(artist_to_listenings, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "result = split.withColumn(\"jaccard\", (col(\"count\")/(AtoL(col(\"A\"))+AtoL(col(\"B\"))-col(\"count\")))).drop('col')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_129 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_131 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_2 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_19 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_111 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_93 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_38 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_80 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_75 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_68 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_27 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_47 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_61 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_23 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_71 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_120 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_181 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_25 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_32 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_187 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_59 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_109 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_114 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_67 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_7 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_11 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_73 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_17 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_95 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_64 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_90 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_185 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_149 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_57 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_116 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_118 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_147 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_191 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_139 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_49 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_158 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_103 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_175 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_86 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_125 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_171 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_141 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_179 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_193 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_196 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_77 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_99 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_123 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_5 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_45 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_101 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_167 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_97 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_121 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_177 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_9 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_4 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_160 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_13 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_53 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_34 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_137 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_107 !\n",
      "2023-04-22 08:20:50,713 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_133 !\n",
      "2023-04-22 08:20:50,714 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_29 !\n",
      "2023-04-22 08:20:50,714 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_40 !\n",
      "2023-04-22 08:20:50,714 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_169 !\n",
      "2023-04-22 08:20:50,714 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_63 !\n",
      "2023-04-22 08:20:50,714 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_51 !\n",
      "2023-04-22 08:20:50,714 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_189 !\n",
      "2023-04-22 08:20:50,714 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_21 !\n",
      "2023-04-22 08:20:50,714 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_36 !\n",
      "2023-04-22 08:20:50,714 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_0 !\n",
      "2023-04-22 08:20:50,714 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_91 !\n",
      "2023-04-22 08:20:50,714 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_30 !\n",
      "2023-04-22 08:20:50,714 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_43 !\n",
      "2023-04-22 08:20:50,714 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_54 !\n",
      "2023-04-22 08:20:50,714 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_15 !\n",
      "2023-04-22 08:20:50,714 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_84 !\n",
      "2023-04-22 08:20:50,714 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_163 !\n",
      "2023-04-22 08:20:50,714 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_145 !\n",
      "2023-04-22 08:20:50,714 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_165 !\n",
      "2023-04-22 08:20:50,714 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_151 !\n",
      "2023-04-22 08:20:50,714 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_88 !\n",
      "2023-04-22 08:20:50,714 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_198 !\n",
      "2023-04-22 08:20:50,714 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_143 !\n",
      "2023-04-22 08:20:50,714 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_183 !\n",
      "2023-04-22 08:20:50,714 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_81 !\n",
      "2023-04-22 08:20:50,714 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_105 !\n",
      "2023-04-22 08:20:50,714 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_156 !\n",
      "2023-04-22 08:20:50,714 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_173 !\n",
      "2023-04-22 08:20:50,714 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_127 !\n",
      "2023-04-22 08:20:50,714 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_135 !\n",
      "2023-04-22 08:20:50,714 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_161 !\n",
      "2023-04-22 08:20:50,714 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_153 !\n",
      "2023-04-22 08:20:50,801 ERROR cluster.YarnScheduler: Lost executor 2 on cf738aa2b563: Container from a bad node: container_1680204499076_0016_01_000003 on host: cf738aa2b563. Exit status: 137. Diagnostics: [2023-04-22 08:20:50.719]Container killed on request. Exit code is 137\n",
      "[2023-04-22 08:20:50.719]Container exited with a non-zero exit code 137. \n",
      "[2023-04-22 08:20:50.720]Killed by external signal\n",
      ".\n",
      "2023-04-22 08:20:50,805 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 2 for reason Container from a bad node: container_1680204499076_0016_01_000003 on host: cf738aa2b563. Exit status: 137. Diagnostics: [2023-04-22 08:20:50.719]Container killed on request. Exit code is 137\n",
      "[2023-04-22 08:20:50.719]Container exited with a non-zero exit code 137. \n",
      "[2023-04-22 08:20:50.720]Killed by external signal\n",
      ".\n",
      "2023-04-22 08:20:50,807 WARN scheduler.TaskSetManager: Lost task 1.0 in stage 90.0 (TID 1718) (cf738aa2b563 executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container from a bad node: container_1680204499076_0016_01_000003 on host: cf738aa2b563. Exit status: 137. Diagnostics: [2023-04-22 08:20:50.719]Container killed on request. Exit code is 137\n",
      "[2023-04-22 08:20:50.719]Container exited with a non-zero exit code 137. \n",
      "[2023-04-22 08:20:50.720]Killed by external signal\n",
      ".\n",
      "2023-04-22 08:21:04,682 WARN scheduler.TaskSetManager: Lost task 1.1 in stage 90.0 (TID 1719) (cf738aa2b563 executor 3): FetchFailed(null, shuffleId=15, mapIndex=-1, mapId=-1, reduceId=72, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 15 partition 72\n",
      "\tat org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:208)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      ")\n",
      "2023-04-22 08:21:05,260 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_140 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_192 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_159 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_162 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_60 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_48 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_39 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_154 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_132 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_157 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_130 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_138 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_87 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_126 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_79 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_18 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_22 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_112 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_188 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_33 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_46 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_134 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_108 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_62 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_85 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_110 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_3 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_92 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_98 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_172 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_41 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_122 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_20 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_55 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_186 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_24 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_37 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_58 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_69 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_170 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_182 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_194 !\n",
      "2023-04-22 08:21:05,261 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_115 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_16 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_26 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_146 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_174 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_35 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_150 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_124 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_10 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_102 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_142 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_44 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_6 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_117 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_128 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_168 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_176 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_50 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_70 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_100 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_184 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_76 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_155 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_152 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_52 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_12 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_72 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_8 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_106 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_148 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_178 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_1 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_82 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_96 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_180 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_104 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_94 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_136 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_66 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_89 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_195 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_166 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_74 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_190 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_199 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_78 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_164 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_113 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_42 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_119 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_197 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_144 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_14 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_83 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_56 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_28 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_65 !\n",
      "2023-04-22 08:21:05,262 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_31 !\n",
      "2023-04-22 08:21:05,469 ERROR cluster.YarnScheduler: Lost executor 1 on cf738aa2b563: Container from a bad node: container_1680204499076_0016_01_000002 on host: cf738aa2b563. Exit status: 137. Diagnostics: [2023-04-22 08:21:05.277]Container killed on request. Exit code is 137\n",
      "[2023-04-22 08:21:05.277]Container exited with a non-zero exit code 137. \n",
      "[2023-04-22 08:21:05.277]Killed by external signal\n",
      ".\n",
      "2023-04-22 08:21:05,469 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 1 for reason Container from a bad node: container_1680204499076_0016_01_000002 on host: cf738aa2b563. Exit status: 137. Diagnostics: [2023-04-22 08:21:05.277]Container killed on request. Exit code is 137\n",
      "[2023-04-22 08:21:05.277]Container exited with a non-zero exit code 137. \n",
      "[2023-04-22 08:21:05.277]Killed by external signal\n",
      ".\n",
      "2023-04-22 08:21:05,469 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 90.0 (TID 1717) (cf738aa2b563 executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Container from a bad node: container_1680204499076_0016_01_000002 on host: cf738aa2b563. Exit status: 137. Diagnostics: [2023-04-22 08:21:05.277]Container killed on request. Exit code is 137\n",
      "[2023-04-22 08:21:05.277]Container exited with a non-zero exit code 137. \n",
      "[2023-04-22 08:21:05.277]Killed by external signal\n",
      ".\n",
      "2023-04-22 08:21:34,799 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_140 !\n",
      "2023-04-22 08:21:34,799 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_192 !\n",
      "2023-04-22 08:21:34,799 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_162 !\n",
      "2023-04-22 08:21:34,799 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_60 !\n",
      "2023-04-22 08:21:34,799 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_19 !\n",
      "2023-04-22 08:21:34,799 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_111 !\n",
      "2023-04-22 08:21:34,799 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_38 !\n",
      "2023-04-22 08:21:34,799 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_48 !\n",
      "2023-04-22 08:21:34,799 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_80 !\n",
      "2023-04-22 08:21:34,799 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_75 !\n",
      "2023-04-22 08:21:34,799 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_68 !\n",
      "2023-04-22 08:21:34,799 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_154 !\n",
      "2023-04-22 08:21:34,799 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_27 !\n",
      "2023-04-22 08:21:34,799 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_132 !\n",
      "2023-04-22 08:21:34,799 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_130 !\n",
      "2023-04-22 08:21:34,799 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_138 !\n",
      "2023-04-22 08:21:34,799 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_23 !\n",
      "2023-04-22 08:21:34,799 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_87 !\n",
      "2023-04-22 08:21:34,799 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_188 !\n",
      "2023-04-22 08:21:34,799 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_46 !\n",
      "2023-04-22 08:21:34,799 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_134 !\n",
      "2023-04-22 08:21:34,799 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_25 !\n",
      "2023-04-22 08:21:34,799 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_32 !\n",
      "2023-04-22 08:21:34,799 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_108 !\n",
      "2023-04-22 08:21:34,799 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_62 !\n",
      "2023-04-22 08:21:34,799 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_109 !\n",
      "2023-04-22 08:21:34,799 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_85 !\n",
      "2023-04-22 08:21:34,799 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_3 !\n",
      "2023-04-22 08:21:34,799 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_92 !\n",
      "2023-04-22 08:21:34,799 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_98 !\n",
      "2023-04-22 08:21:34,799 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_7 !\n",
      "2023-04-22 08:21:34,799 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_11 !\n",
      "2023-04-22 08:21:34,799 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_172 !\n",
      "2023-04-22 08:21:34,799 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_73 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_17 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_64 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_186 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_58 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_170 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_182 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_158 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_194 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_125 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_115 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_146 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_77 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_174 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_123 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_5 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_150 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_121 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_102 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_9 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_142 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_160 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_44 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_117 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_13 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_34 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_168 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_176 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_50 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_70 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_100 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_184 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_152 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_52 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_72 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_29 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_40 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_106 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_148 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_178 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_96 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_180 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_104 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_94 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_21 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_36 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_136 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_0 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_66 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_89 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_195 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_54 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_15 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_166 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_190 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_199 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_164 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_113 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_42 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_119 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_197 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_144 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_83 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_56 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_81 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_156 !\n",
      "2023-04-22 08:21:34,800 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_127 !\n",
      "2023-04-22 08:21:35,021 ERROR cluster.YarnScheduler: Lost executor 4 on cf738aa2b563: Container from a bad node: container_1680204499076_0016_01_000005 on host: cf738aa2b563. Exit status: 137. Diagnostics: [2023-04-22 08:21:34.809]Container killed on request. Exit code is 137\n",
      "[2023-04-22 08:21:34.809]Container exited with a non-zero exit code 137. \n",
      "[2023-04-22 08:21:34.810]Killed by external signal\n",
      ".\n",
      "2023-04-22 08:21:35,021 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 4 for reason Container from a bad node: container_1680204499076_0016_01_000005 on host: cf738aa2b563. Exit status: 137. Diagnostics: [2023-04-22 08:21:34.809]Container killed on request. Exit code is 137\n",
      "[2023-04-22 08:21:34.809]Container exited with a non-zero exit code 137. \n",
      "[2023-04-22 08:21:34.810]Killed by external signal\n",
      ".\n",
      "2023-04-22 08:21:35,022 WARN scheduler.TaskSetManager: Lost task 1.0 in stage 90.1 (TID 2345) (cf738aa2b563 executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container from a bad node: container_1680204499076_0016_01_000005 on host: cf738aa2b563. Exit status: 137. Diagnostics: [2023-04-22 08:21:34.809]Container killed on request. Exit code is 137\n",
      "[2023-04-22 08:21:34.809]Container exited with a non-zero exit code 137. \n",
      "[2023-04-22 08:21:34.810]Killed by external signal\n",
      ".\n",
      "2023-04-22 08:21:47,223 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_129 !\n",
      "2023-04-22 08:21:47,223 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_131 !\n",
      "2023-04-22 08:21:47,223 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_2 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_159 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_93 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_39 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_47 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_61 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_157 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_126 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_71 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_79 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_18 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_22 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_112 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_120 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_181 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_33 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_187 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_59 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_110 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_114 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_67 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_95 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_41 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_122 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_90 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_185 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_149 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_57 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_20 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_55 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_24 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_116 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_118 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_37 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_69 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_147 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_191 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_139 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_49 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_103 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_175 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_86 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_171 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_141 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_179 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_16 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_193 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_26 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_196 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_99 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_35 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_45 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_101 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_167 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_97 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_124 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_10 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_177 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_4 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_6 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_128 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_53 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_137 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_107 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_76 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_155 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_133 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_12 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_8 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_169 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_1 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_82 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_63 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_51 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_189 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_91 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_30 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_43 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_84 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_163 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_74 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_145 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_165 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_151 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_88 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_78 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_198 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_14 !\n",
      "2023-04-22 08:21:47,224 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_143 !\n",
      "2023-04-22 08:21:47,225 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_183 !\n",
      "2023-04-22 08:21:47,225 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_28 !\n",
      "2023-04-22 08:21:47,225 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_65 !\n",
      "2023-04-22 08:21:47,225 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_105 !\n",
      "2023-04-22 08:21:47,225 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_173 !\n",
      "2023-04-22 08:21:47,225 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_31 !\n",
      "2023-04-22 08:21:47,225 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_135 !\n",
      "2023-04-22 08:21:47,225 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_161 !\n",
      "2023-04-22 08:21:47,225 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_36_153 !\n",
      "2023-04-22 08:21:47,431 ERROR cluster.YarnScheduler: Lost executor 3 on cf738aa2b563: Container from a bad node: container_1680204499076_0016_01_000004 on host: cf738aa2b563. Exit status: 137. Diagnostics: [2023-04-22 08:21:47.234]Container killed on request. Exit code is 137\n",
      "[2023-04-22 08:21:47.234]Container exited with a non-zero exit code 137. \n",
      "[2023-04-22 08:21:47.235]Killed by external signal\n",
      ".\n",
      "2023-04-22 08:21:47,432 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 3 for reason Container from a bad node: container_1680204499076_0016_01_000004 on host: cf738aa2b563. Exit status: 137. Diagnostics: [2023-04-22 08:21:47.234]Container killed on request. Exit code is 137\n",
      "[2023-04-22 08:21:47.234]Container exited with a non-zero exit code 137. \n",
      "[2023-04-22 08:21:47.235]Killed by external signal\n",
      ".\n",
      "2023-04-22 08:21:47,432 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 90.1 (TID 2344) (cf738aa2b563 executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Container from a bad node: container_1680204499076_0016_01_000004 on host: cf738aa2b563. Exit status: 137. Diagnostics: [2023-04-22 08:21:47.234]Container killed on request. Exit code is 137\n",
      "[2023-04-22 08:21:47.234]Container exited with a non-zero exit code 137. \n",
      "[2023-04-22 08:21:47.235]Killed by external signal\n",
      ".\n",
      "2023-04-22 08:21:47,541 WARN scheduler.TaskSetManager: Lost task 1.1 in stage 90.1 (TID 2346) (cf738aa2b563 executor 5): FetchFailed(null, shuffleId=15, mapIndex=-1, mapId=-1, reduceId=72, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 15 partition 72\n",
      "\tat org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:208)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      ")\n",
      "2023-04-22 08:21:47,568 WARN scheduler.TaskSetManager: Lost task 0.1 in stage 90.1 (TID 2347) (cf738aa2b563 executor 5): FetchFailed(null, shuffleId=15, mapIndex=-1, mapId=-1, reduceId=0, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 15 partition 0\n",
      "\tat org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:208)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      ")\n",
      "ERROR:root:Exception while sending command.                         (0 + 2) / 2]\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o213.count",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjaccard\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjaccard is not null\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py:680\u001b[0m, in \u001b[0;36mDataFrame.count\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcount\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    671\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the number of rows in this :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m    672\u001b[0m \n\u001b[1;32m    673\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;124;03m    2\u001b[39;00m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 680\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py:111\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m py4j\u001b[38;5;241m.\u001b[39mprotocol\u001b[38;5;241m.\u001b[39mPy4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    113\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/protocol.py:334\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m                 \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 334\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    335\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    336\u001b[0m             \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name))\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m=\u001b[39m answer[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o213.count"
     ]
    }
   ],
   "source": [
    "result.select('jaccard').filter('jaccard is not null').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "res = {\"q1\": 2889, \"q2\": 6838579}\n",
    "with open(\"week5.json\", \"w\") as f:\n",
    "    json.dump(res, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!doctype html>\n",
      "<html lang=en>\n",
      "<title>500 Internal Server Error</title>\n",
      "<h1>Internal Server Error</h1>\n",
      "<p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.</p>\n"
     ]
    }
   ],
   "source": [
    "! curl -F file=@week5.json \"51.250.54.133:80/MDS-LSML1/kewlsid96/w6/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "lab-task-5a2a5e"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "5f4626d50a060da4b47e18776c852ab1c193f00f2162881a84608752df882344"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
