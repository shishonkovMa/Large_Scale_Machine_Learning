{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"../cluster\" style=\"font-size:20px\">All Applications (YARN)</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework\n",
    "\n",
    "_This task is very similar to the one you have already done on Hadoop. It should be so, appreciate how much easier it is to solve on Spark._\n",
    "\n",
    "We will use the logs of listening to music artists in the Yandex.Music service.\n",
    "\n",
    "The `events.csv` file contains entries like `User,Artist,Number of plays,Number of skips`:\n",
    "```csv\n",
    "userId,artistId,plays,skips\n",
    "0,335,1,0\n",
    "0,708,1,0\n",
    "0,710,2,1\n",
    "0,815,1,1\n",
    "```\n",
    "\n",
    "You need to do the following:\n",
    "1. **Leave in the data only those users for whom the sum of plays is strictly greater than 2000. How many such users?**\n",
    "2. **In the data filtered at the first step, find the 5 most popular performers by the number of users (identifiers).**\n",
    "\n",
    "Details:\n",
    "1. Let's assume that a single user's playlist always fits in memory.\n",
    "\n",
    "Save the solution to the `result.json` file. \n",
    "File content example:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"q1\": 123,\n",
    "    \"q2\": [\n",
    "        4,\n",
    "        5,\n",
    "        6,\n",
    "        7,\n",
    "        8\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId,artistId,plays,skips\n",
      "0,335,1,0\n",
      "0,708,1,0\n",
      "0,710,2,1\n",
      "0,815,1,1\n"
     ]
    }
   ],
   "source": [
    "# file content example\n",
    "! head -n 5 yandex_music/events.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copyFromLocal: `/yandex_music/events.csv': File exists\n",
      "copyFromLocal: `/yandex_music/artists.jsonl': File exists\n",
      "copyFromLocal: `/yandex_music/README.txt': File exists\n",
      "Found 3 items\n",
      "-rw-r--r--   1 jovyan supergroup        254 2023-04-19 14:44 /yandex_music/README.txt\n",
      "-rw-r--r--   1 jovyan supergroup      3.7 M 2023-04-19 14:44 /yandex_music/artists.jsonl\n",
      "-rw-r--r--   1 jovyan supergroup     47.6 M 2023-04-19 14:44 /yandex_music/events.csv\n"
     ]
    }
   ],
   "source": [
    "# copy files to HDFS\n",
    "! hadoop fs -copyFromLocal yandex_music /\n",
    "! hadoop fs -ls -h /yandex_music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "2023-04-19 17:22:10,041 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "# https://spark.apache.org/docs/latest/rdd-programming-guide.html\n",
    "# http://spark.apache.org/docs/latest/sql-getting-started.html\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext(appName='jupyter')\n",
    "\n",
    "from pyspark.sql import SparkSession, Row\n",
    "se = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>artistId</th>\n",
       "      <th>plays</th>\n",
       "      <th>skips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>335</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>708</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>710</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>815</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  userId artistId plays skips\n",
       "0      0      335     1     0\n",
       "1      0      708     1     0\n",
       "2      0      710     2     1\n",
       "3      0      815     1     1\n",
       "4      0      880     1     1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load csv as Spark DataFrame\n",
    "events = se.read.csv(\"hdfs:///yandex_music/events.csv\", header=True)  # в первой строке у нас заголовок\n",
    "events.registerTempTable(\"events\")\n",
    "events.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(userId='0', artistId='335', plays='1', skips='0'),\n",
       " Row(userId='0', artistId='708', plays='1', skips='0'),\n",
       " Row(userId='0', artistId='710', plays='2', skips='1'),\n",
       " Row(userId='0', artistId='815', plays='1', skips='1'),\n",
       " Row(userId='0', artistId='880', plays='1', skips='1')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can convert this DataFrame to RDD\n",
    "events.rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('userId', 'string'),\n",
       " ('artistId', 'string'),\n",
       " ('plays', 'string'),\n",
       " ('skips', 'string')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fetch the data types of each column\n",
    "events.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, sum\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "events = events.withColumn(\"plays\", col(\"plays\").cast(IntegerType()))\n",
    "events = events.withColumn(\"skips\", col(\"skips\").cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('userId', 'string'),\n",
       " ('artistId', 'string'),\n",
       " ('plays', 'int'),\n",
       " ('skips', 'int')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:====================================================>    (11 + 1) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|userID|total|\n",
      "+------+-----+\n",
      "|   718| 2063|\n",
      "|   711| 2439|\n",
      "|   700| 2496|\n",
      "|   886| 3294|\n",
      "|  1236| 2622|\n",
      "|  1041| 3470|\n",
      "|  1093| 3525|\n",
      "|  1192| 3288|\n",
      "|   685| 2779|\n",
      "|   836| 2266|\n",
      "|  1099| 2073|\n",
      "|   863| 2687|\n",
      "|   991| 2064|\n",
      "|  1100| 2744|\n",
      "|   710| 3381|\n",
      "|  1012| 3085|\n",
      "|  1314| 3455|\n",
      "|   652| 3087|\n",
      "|   924| 3374|\n",
      "|   878| 3570|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# group by userID and get the sum \n",
    "new_events = events.groupBy(\"userID\").agg(sum(\"plays\").alias(\"total\"))\n",
    "\n",
    "# filter userIDs which have count greater than 2000\n",
    "user_id = new_events.filter(col(\"total\") > 2000)\n",
    "user_id.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:====================================================>    (11 + 1) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-----+-----+-----+\n",
      "|userId|artistId|plays|skips|total|\n",
      "+------+--------+-----+-----+-----+\n",
      "|   125|      50|    2|    0| 3176|\n",
      "|   125|     335|    8|    0| 3176|\n",
      "|   125|     425|    2|    0| 3176|\n",
      "|   125|     854|    7|    1| 3176|\n",
      "|   125|     868|    2|    0| 3176|\n",
      "|   125|    1091|    1|    0| 3176|\n",
      "|   125|    1123|    1|    0| 3176|\n",
      "|   125|    1179|    1|    0| 3176|\n",
      "|   125|    1202|    1|    0| 3176|\n",
      "|   125|    1555|    2|    0| 3176|\n",
      "|   125|    1897|    2|    3| 3176|\n",
      "|   125|    1993|    8|    0| 3176|\n",
      "|   125|    2130|    1|    0| 3176|\n",
      "|   125|    2147|    1|    0| 3176|\n",
      "|   125|    2162|    1|    0| 3176|\n",
      "|   125|    2267|    1|    0| 3176|\n",
      "|   125|    2388|    1|    0| 3176|\n",
      "|   125|    2922|    3|    0| 3176|\n",
      "|   125|    3091|    5|    0| 3176|\n",
      "|   125|    3104|    1|    0| 3176|\n",
      "+------+--------+-----+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "new_joined_df = events.join(user_id, \"userID\")\n",
    "new_joined_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1705"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_values = new_joined_df.select(\"userId\").distinct()\n",
    "q1 = unique_values.count()\n",
    "q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 26:============================================>           (19 + 2) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|artistId|count|\n",
      "+--------+-----+\n",
      "|   11368| 1421|\n",
      "|    3629| 1274|\n",
      "|     259| 1221|\n",
      "|   44148| 1191|\n",
      "|   23524| 1167|\n",
      "|   59783| 1138|\n",
      "|   21042| 1067|\n",
      "|   21643| 1037|\n",
      "|   20272| 1035|\n",
      "|     645| 1032|\n",
      "|    3568| 1026|\n",
      "|   23595| 1023|\n",
      "|   28412| 1011|\n",
      "|   63958| 1007|\n",
      "|   48965|  985|\n",
      "|   64965|  983|\n",
      "|   36545|  970|\n",
      "|   48246|  961|\n",
      "|   34243|  960|\n",
      "|   45433|  958|\n",
      "+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "artist_count = new_joined_df.groupBy(\"artistId\").count()\n",
    "sorted_artist_count = artist_count.orderBy(desc(\"count\"))\n",
    "sorted_artist_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 35:==============================================>         (20 + 2) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|artistId|count|\n",
      "+--------+-----+\n",
      "|   11368| 1421|\n",
      "|    3629| 1274|\n",
      "|     259| 1221|\n",
      "|   44148| 1191|\n",
      "|   23524| 1167|\n",
      "+--------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sorted_artist_count=sorted_artist_count.limit(5)\n",
    "sorted_artist_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 45:==============================================>         (20 + 2) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['11368', '3629', '259', '44148', '23524']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "artist_ids=[]\n",
    "for val in sorted_artist_count.collect():\n",
    "    artist_ids.append(val[\"artistId\"])\n",
    "print(artist_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! echo '{ \"q1\": 1705, \"q2\": [ 11368, 3629, 259, 44148, 23524 ] }' > result.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "Correct q1 answer! Correct q2 answer!\n"
     ]
    }
   ],
   "source": [
    "! curl -F file=@result.json \"51.250.54.133:80/MDS-LSML1/mishafoniakov/w2/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# stop Spark (and YARN application)\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
